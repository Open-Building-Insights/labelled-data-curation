{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9_data_labeling\n",
    "### Splits the curated labelled data set to testing, validation and training subsets\n",
    "### See and adjust if needed the cell below defining non-residential building types: new_nonresidential_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial configuration\n",
    "#### To start working with this particular notebook, you need to provide necessary credential and settings\n",
    "#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n",
    "    \"\"\"\n",
    "    {\n",
    "    \"COS_ENDPOINT_URL\": \"s3.private.eu-de.cloud-object-storage.appdomain.cloud\",\n",
    "    \"COS_AUTH_ENDPOINT_URL\": \"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    \"COS_APIKEY\": \"xxx\",\n",
    "    \"DATA_CURATION_BUCKET\": \"xxx\"\n",
    "    }\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read notebook configuration\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "config_str = getpass.getpass('Enter your prepared config: ')\n",
    "config = json.loads(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "import io, os, sys, traceback\n",
    "import shapely.geometry as G\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib.path import Path\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, mapping, Point, MultiPolygon\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "from pyproj import Geod\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "import shapely\n",
    "import ibm_boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "geod = Geod(ellps=\"WGS84\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init S3 client in order to upload data to the curation bucket\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "                              ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "                              ibm_auth_endpoint=config[\"COS_AUTH_ENDPOINT_URL\"],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config[\"COS_ENDPOINT_URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cinfig necessary variables\n",
    "labelled_data_SMOD_heights_sentinel2_parquet = 'all_labelled_data_SMOD_heights_sentinel2.parquet'\n",
    "labelled_data_finished_split = 'all_merged_L1_SMOD_heights_images.parquet'\n",
    "curation_bucket = config[\"DATA_CURATION_BUCKET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the labelled data set with all info\n",
    "if type(curation_bucket) == str:\n",
    "\n",
    "    streaming_body = cos_client.get_object(Bucket=curation_bucket, Key=labelled_data_SMOD_heights_sentinel2_parquet)['Body']\n",
    "    print(\"Downloading to local storage :  \" + labelled_data_SMOD_heights_sentinel2_parquet)\n",
    "    with io.FileIO(labelled_data_SMOD_heights_sentinel2_parquet, 'w') as file:\n",
    "        for i in io.BytesIO(streaming_body.read()):\n",
    "            file.write(i)\n",
    "\n",
    "ML_df = gpd.read_parquet(labelled_data_SMOD_heights_sentinel2_parquet)\n",
    "ML_df.columns\n",
    "ML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nonresidential_types = [\n",
    "    # 'residential',\n",
    "    # 'house',\n",
    "    # 'hut',\n",
    "    # 'shed',\n",
    "    'construction',\n",
    "    'cb',\n",
    "    'garage',\n",
    "    'detached',\n",
    "    'place_of_worship',\n",
    "    'library',\n",
    "    'fuel',\n",
    "    'yes',\n",
    "    'aerodrome',\n",
    "    'education',\n",
    "    'religious',\n",
    "    'agricultural',\n",
    "    'bank',\n",
    "    'ruins',\n",
    "    'hostel',\n",
    "    'bungalow',\n",
    "    'no',\n",
    "    # 'apartments',\n",
    "    'roof',\n",
    "    'storage_tank',\n",
    "    'fire_station',\n",
    "    'institutional',\n",
    "    'mall',\n",
    "    'car',\n",
    "    'police',\n",
    "    'plant',\n",
    "    'quarry',\n",
    "    'entertainment',\n",
    "    'carport',\n",
    "    'greenhouse_horticulture',\n",
    "    'cinema',\n",
    "    'terrace',\n",
    "    'track',\n",
    "    'dormitory',\n",
    "    # 'guest_house',\n",
    "    'gatehouse',\n",
    "    'pavilion',\n",
    "    'medical',\n",
    "    'cabin',\n",
    "    'theatre',\n",
    "    'semidetached_house',\n",
    "    'multipolygon',\n",
    "    'garages',\n",
    "    'gate',\n",
    "    'construction(1)',\n",
    "    'construction(2)',\n",
    "    'construction(3)',\n",
    "    'silo',\n",
    "    'farmyard',\n",
    "    'grandstand',\n",
    "    'tent',\n",
    "    'container',\n",
    "    'toilets',\n",
    "    'bridge',\n",
    "    'chri',\n",
    "    'observing tower',\n",
    "    'foundation',\n",
    "    'diplomatic',\n",
    "    'sty',\n",
    "    'foundaction',\n",
    "    'parking',\n",
    "    'CBA_HOUSE',\n",
    "    'consturuction',\n",
    "    'gazebo',\n",
    "    'utility',\n",
    "    'commercial;residenti',\n",
    "    'commercia;lresidenti',\n",
    "    'unkown',\n",
    "    'open-air',\n",
    "    'Maya Primary School',\n",
    "    'swimming pool',\n",
    "    'collapsed',\n",
    "    'allotment_house',\n",
    "    'co operative bank at',\n",
    "    'abandoned'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'nonresidential': 100253, 'residential': 67066})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonresidentialtypes = [\n",
    "    'retail', 'office', 'school', 'commercial', 'university', 'chapel', 'industrial', 'service',\n",
    "    'church', 'hospital', 'government', 'hotel', 'mosque', 'greenhouse', 'hangar', 'farm', 'stadium',\n",
    "    'transportation', 'warehouse', 'clinic', 'public', 'store', 'kitchen', 'Wasini hostel', 'Mortuary',\n",
    "    'commercial;yes', 'Petrol station', 'Dispensary', 'Medical Laboratory', 'manufacture', 'supermarket',\n",
    "    'inn', 'greenhouse_horticult', 'cowshed', 'temple', 'kindergarten', 'barn', 'stable', 'business',\n",
    "    'train_station', 'restaurant', 'college', 'bakehouse', 'civic', 'farm_auxiliary', 'resturant', 'cathedral',\n",
    "    'yes;office', 'static_caravan', 'kiosk', 'monastery', 'convent', 'sports_centre'\n",
    "    ]\n",
    "\n",
    "nonresidentialtypes = nonresidentialtypes + new_nonresidential_types\n",
    "\n",
    "def assign_ML_class(osm_type):\n",
    "    \n",
    "    if osm_type in nonresidentialtypes:\n",
    "        return \"nonresidential\"\n",
    "    else:\n",
    "        return \"residential\"\n",
    "\n",
    "ML_df['L1_class'] = ML_df['osm_type'].apply(lambda x: assign_ML_class(x))\n",
    "\n",
    "\n",
    "Counter(ML_df.L1_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              index_column  split in %\n",
      "image_ML_type L1_class                                \n",
      "test          nonresidential          4018       3.855\n",
      "              residential             6405       6.145\n",
      "train         nonresidential         28129      26.986\n",
      "              residential            44836      43.015\n",
      "validation    nonresidential          8036       7.710\n",
      "              residential            12810      12.290\n"
     ]
    }
   ],
   "source": [
    "# assign appropriate ML tag 70% train, 20% validation 10% test\n",
    "def assign_label(idx):\n",
    "    \n",
    "    if str(idx)[-1] in ['0', '1', '2', '3', '4', '5', '6']:\n",
    "        return 'train'\n",
    "    elif str(idx)[-1] in ['7', '8']:\n",
    "        return 'validation'\n",
    "    elif str(idx)[-1] in ['9']:\n",
    "        return 'test'\n",
    "\n",
    "\n",
    "data_len = len(ML_df)\n",
    "ML_df['index_column'] = [i for i in range(len(ML_df))]\n",
    "ML_df['image_ML_type'] = [\"initval\" for _ in range(len(ML_df))]\n",
    "\n",
    "for ml_class in list(set(ML_df['L1_class'])):\n",
    "    \n",
    "    \n",
    "    ML_df = ML_df.sort_values('area_in_meters', ascending=True)\n",
    "    ml_class_data_idxs = ML_df[ML_df['L1_class'] == ml_class].index.tolist()\n",
    "    for row_idx, df_idx in enumerate(ml_class_data_idxs):\n",
    "        \n",
    "        ML_df.at[df_idx, 'image_ML_type'] = assign_label(row_idx)\n",
    "        \n",
    "split_result = ML_df[['image_ML_type', 'L1_class', 'index_column']].groupby(['image_ML_type', 'L1_class']).count()\n",
    "split_result['split in %'] = round(100 * split_result['index_column'] / data_len, 3)\n",
    "print(split_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_df['area_in_meters'] = ML_df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n",
    "ML_df.to_parquet(labelled_data_finished_split)\n",
    "\n",
    "# optionaly upload file to the bucket\n",
    "if type(curation_bucket) == str:\n",
    "        \n",
    "    try:\n",
    "        cos_client.upload_file(\n",
    "            Filename=labelled_data_finished_split,\n",
    "            Bucket=curation_bucket,\n",
    "            Key=labelled_data_finished_split,\n",
    "            ExtraArgs={'ContentDisposition': 'attachment'}\n",
    "        )\n",
    "           \n",
    "        print(f'File {labelled_data_finished_split} successfully uploaded to the COS {curation_bucket} bucket')\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91mFailed upload file to the bucket {curation_bucket}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

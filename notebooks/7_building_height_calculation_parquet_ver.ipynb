{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 7_building_height_calculation_parquet_ver\n","### Adds the building height to all buildings in the curated labelled building catalog\n","### Building height is not used by the current model as an input for classification, hence it is not used in the training process, because building heights have not improved the models precision. The code itself is retained, nevertheless."]},{"cell_type":"markdown","metadata":{},"source":["### Initial configuration\n","#### To start working with this particular notebook, you need to provide necessary credential and settings\n","#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n","    \"\"\"\n","    {\n","    \"COS_ENDPOINT_URL\": \"s3.private.eu-de.cloud-object-storage.appdomain.cloud\",\n","    \"COS_AUTH_ENDPOINT_URL\": \"https://iam.cloud.ibm.com/oidc/token\",\n","    \"COS_APIKEY\": \"xxx\",\n","    \"DATA_CURATION_BUCKET\": \"xxx\",\n","    \"UTILS_BUCKET\": \"notebook-utils-bucket\",\n","    \"HEIGHTS_TIFF_FILENAME\": \"WSF3Dv3_Kenya.tif\",\n","    \"BUCKET_TIFF\": \"buildings-height-tiffs\"\n","    }\n","    \"\"\"\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Read notebook configuration\n","import getpass\n","import json\n","\n","config_str = getpass.getpass('Enter your prepared config: ')\n","config = json.loads(config_str)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying to localStorage :  Kenya_urban_suburban.json\n","Copying to localStorage :  db2jcc4.jar\n","Copying to localStorage :  utils.py\n","External utils succesfully imported\n"]}],"source":["# Import necessary libraries\n","import io\n","from PIL import Image\n","import ibm_boto3\n","import jaydebeapi as jdbc\n","import jpype\n","from botocore.client import Config\n","import numpy as np\n","import configparser\n","import os\n","import sys\n","from ibm_cloud_sdk_core import ApiException\n","from ibmcloudant.cloudant_v1 import CloudantV1, Document, BulkDocs\n","from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n","import pandas as pd\n","import geopandas as gpd\n","import random\n","import time\n","import base64\n","import shutil\n","import threading\n","from collections import Counter\n","from tqdm import tqdm\n","from datetime import datetime\n","import os\n","import rasterio\n","from rasterio.windows import Window\n","import gc\n","#import cv2\n","from matplotlib.path import Path\n","import matplotlib.pyplot as plt\n","import shapely\n","\n","\n","# # init S3 client in order to work with last tiff file version\n","cos_client = ibm_boto3.client(service_name='s3',\n","                              ibm_api_key_id=config[\"COS_APIKEY\"],\n","                              ibm_auth_endpoint=config[\"COS_AUTH_ENDPOINT_URL\"],\n","                              config=Config(signature_version='oauth'),\n","                              endpoint_url=config[\"COS_ENDPOINT_URL\"])\n","\n","\n","# import external utils library\n","response = cos_client.list_objects_v2(Bucket=config[\"UTILS_BUCKET\"])\n","\n","try:\n","    for obj in response['Contents']:\n","        name = obj['Key']\n","        streaming_body_1 = cos_client.get_object(Bucket=config[\"UTILS_BUCKET\"], Key=name)['Body']\n","        print(\"Copying to localStorage :  \" + name)\n","        with io.FileIO(name, 'w') as file:\n","            for i in io.BytesIO(streaming_body_1.read()):\n","                file.write(i)\n","    \n","    from utils import *\n","    print('External utils succesfully imported')\n","except Exception as e:\n","    print('Error occured: ', e)\n","    "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# assign cinfig necessary variables\n","BUCKET_TIFF = config[\"BUCKET_TIFF\"]\n","heights_tiff_name = config[\"HEIGHTS_TIFF_FILENAME\"]\n","labelled_data_SMOD_parquet = 'all_labelled_data_SMOD.parquet'\n","labelled_data_SMOD_heights_parquet = 'all_labelled_data_SMOD_heights.parquet'\n","curation_bucket = config[\"DATA_CURATION_BUCKET\"]"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Recreate /tiff directories\n"]},{"name":"stdout","output_type":"stream","text":["Copying to localStorage: tiff/WSF3Dv3_Kenya.tif\n","Successfully downloaded\n"]}],"source":["# paths for local storing of tiff files\n","path_to_tif_folder = 'tiff/'\n","\n","# clear files in directories if exist\n","try:\n","    shutil.rmtree(path_to_tif_folder, ignore_errors=True)\n","except Exception as e:\n","    print(e)\n","\n","print(\"Recreate /tiff directories\")\n","os.makedirs(os.path.dirname(path_to_tif_folder), exist_ok=True)\n","\n","# download heights tiff file\n","streaming_body = cos_client.get_object(Bucket=BUCKET_TIFF, Key=heights_tiff_name)['Body']      \n","with io.FileIO(path_to_tif_folder + heights_tiff_name, 'w') as file:\n","    print(\"Copying to localStorage: \" + path_to_tif_folder + heights_tiff_name)\n","    for i in io.BytesIO(streaming_body.read()):\n","        file.write(i)\n","\n","print('Successfully downloaded')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'driver': 'GTiff', 'dtype': 'float64', 'nodata': None, 'width': 111543, 'height': 133808, 'count': 1, 'crs': CRS.from_epsg(4326), 'transform': Affine(8.983152841195211e-05, 0.0, 31.98999541430869,\n","       0.0, -8.983152841195211e-05, 6.010088576873247), 'blockysize': 1, 'tiled': False, 'compress': 'lzw', 'interleave': 'band'}\n","tile_width: 11154, tile_height: 13380\n","TIFf image wiil be divided to 11 rows and 11 cols\n","121\n"]}],"source":["#open heights tiff \n","dat = rasterio.open(os.path.join(path_to_tif_folder, heights_tiff_name))\n","profile = dat.profile.copy()\n","profile.update(compress='lzw')\n","print(profile)\n","\n","#divide tiff to tiles\n","tiff_width = profile['width']\n","tiff_height = profile['height']\n","\n","tile_width = int(tiff_width / 10)\n","tile_height = int(tiff_height / 10)\n","\n","print(f'tile_width: {tile_width}, tile_height: {tile_height}')\n","# define overlap between tiles\n","overlap = 500\n","\n","columns_amount = int(tiff_width / tile_width) if tiff_width % tile_width == 0 else int(tiff_width / tile_width) + 1\n","rows_amount = int(tiff_height / tile_height) if tiff_height % tile_height == 0 else int(tiff_height / tile_height) + 1\n","print(f'TIFf image wiil be divided to {rows_amount} rows and {columns_amount} cols')\n","\n","images_coords = []\n","\n","for col_idx in range(1, columns_amount + 1):\n","    \n","    row_start = max(tile_width * (col_idx - 1) - overlap, 0)\n","    \n","    if col_idx != columns_amount:\n","        \n","        row_limits = [row_start, tile_width * col_idx]\n","    elif col_idx == columns_amount:\n","        row_limits = [row_start, tiff_width]\n","    \n","    for row_idx in range(1, rows_amount + 1):\n","        \n","        col_start = max(tile_height * (row_idx - 1) - overlap, 0)\n","        \n","        if row_idx != columns_amount:\n","            col_limits = [col_start, tile_height * row_idx]\n","        elif row_idx == columns_amount:\n","            col_limits = [col_start, tiff_height]\n","            \n","        coords = [col_limits, row_limits]\n","        images_coords.append(coords)\n","        \n","print(len(images_coords))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>vida_confidence</th>\n","      <th>geometry</th>\n","      <th>building_area_in_meters</th>\n","      <th>county</th>\n","      <th>SMOD_name</th>\n","      <th>SMOD_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5588</th>\n","      <td>-0.883311</td>\n","      <td>35.014648</td>\n","      <td>0.7856</td>\n","      <td>POLYGON ((35.01468 -0.88330, 35.01463 -0.88329...</td>\n","      <td>21.586176</td>\n","      <td>Bomet</td>\n","      <td>Dense and semi-dense urban cluster (Town)</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5606</th>\n","      <td>-0.882994</td>\n","      <td>35.014654</td>\n","      <td>0.0000</td>\n","      <td>POLYGON ((35.01468 -0.88302, 35.01468 -0.88298...</td>\n","      <td>25.149882</td>\n","      <td>Bomet</td>\n","      <td>Dense and semi-dense urban cluster (Town)</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5614</th>\n","      <td>-0.883239</td>\n","      <td>35.014658</td>\n","      <td>0.8072</td>\n","      <td>POLYGON ((35.01468 -0.88326, 35.01468 -0.88321...</td>\n","      <td>24.440989</td>\n","      <td>Bomet</td>\n","      <td>Suburban or peri-urban cells (Suburb)</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6765</th>\n","      <td>-0.882690</td>\n","      <td>35.015054</td>\n","      <td>0.7530</td>\n","      <td>POLYGON ((35.01507 -0.88271, 35.01507 -0.88267...</td>\n","      <td>22.086248</td>\n","      <td>Bomet</td>\n","      <td>Suburban or peri-urban cells (Suburb)</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7126</th>\n","      <td>-0.883227</td>\n","      <td>35.015184</td>\n","      <td>0.8424</td>\n","      <td>POLYGON ((35.01521 -0.88320, 35.01516 -0.88320...</td>\n","      <td>35.753080</td>\n","      <td>Bomet</td>\n","      <td>Suburban or peri-urban cells (Suburb)</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1024172</th>\n","      <td>-1.263098</td>\n","      <td>37.096335</td>\n","      <td>0.8918</td>\n","      <td>POLYGON ((37.09638 -1.26312, 37.09637 -1.26310...</td>\n","      <td>81.492523</td>\n","      <td>Nairobi</td>\n","      <td>Low density rural grids cells (Dispersed rural...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1024188</th>\n","      <td>-1.266434</td>\n","      <td>37.101554</td>\n","      <td>0.8751</td>\n","      <td>POLYGON ((37.10160 -1.26645, 37.10158 -1.26639...</td>\n","      <td>72.363677</td>\n","      <td>Nairobi</td>\n","      <td>Low density rural grids cells (Dispersed rural...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1024189</th>\n","      <td>-1.268861</td>\n","      <td>37.101554</td>\n","      <td>0.8099</td>\n","      <td>POLYGON ((37.10157 -1.26883, 37.10155 -1.26885...</td>\n","      <td>41.212594</td>\n","      <td>Nairobi</td>\n","      <td>Low density rural grids cells (Dispersed rural...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1024217</th>\n","      <td>-1.265807</td>\n","      <td>37.101614</td>\n","      <td>0.8286</td>\n","      <td>POLYGON ((37.10165 -1.26583, 37.10164 -1.26577...</td>\n","      <td>45.291012</td>\n","      <td>Nairobi</td>\n","      <td>Low density rural grids cells (Dispersed rural...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1024253</th>\n","      <td>-1.265743</td>\n","      <td>37.101679</td>\n","      <td>0.9105</td>\n","      <td>POLYGON ((37.10173 -1.26579, 37.10172 -1.26569...</td>\n","      <td>101.285402</td>\n","      <td>Nairobi</td>\n","      <td>Low density rural grids cells (Dispersed rural...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1706368 rows × 8 columns</p>\n","</div>"],"text/plain":["         latitude  longitude  vida_confidence  \\\n","5588    -0.883311  35.014648           0.7856   \n","5606    -0.882994  35.014654           0.0000   \n","5614    -0.883239  35.014658           0.8072   \n","6765    -0.882690  35.015054           0.7530   \n","7126    -0.883227  35.015184           0.8424   \n","...           ...        ...              ...   \n","1024172 -1.263098  37.096335           0.8918   \n","1024188 -1.266434  37.101554           0.8751   \n","1024189 -1.268861  37.101554           0.8099   \n","1024217 -1.265807  37.101614           0.8286   \n","1024253 -1.265743  37.101679           0.9105   \n","\n","                                                  geometry  \\\n","5588     POLYGON ((35.01468 -0.88330, 35.01463 -0.88329...   \n","5606     POLYGON ((35.01468 -0.88302, 35.01468 -0.88298...   \n","5614     POLYGON ((35.01468 -0.88326, 35.01468 -0.88321...   \n","6765     POLYGON ((35.01507 -0.88271, 35.01507 -0.88267...   \n","7126     POLYGON ((35.01521 -0.88320, 35.01516 -0.88320...   \n","...                                                    ...   \n","1024172  POLYGON ((37.09638 -1.26312, 37.09637 -1.26310...   \n","1024188  POLYGON ((37.10160 -1.26645, 37.10158 -1.26639...   \n","1024189  POLYGON ((37.10157 -1.26883, 37.10155 -1.26885...   \n","1024217  POLYGON ((37.10165 -1.26583, 37.10164 -1.26577...   \n","1024253  POLYGON ((37.10173 -1.26579, 37.10172 -1.26569...   \n","\n","         building_area_in_meters   county  \\\n","5588                   21.586176    Bomet   \n","5606                   25.149882    Bomet   \n","5614                   24.440989    Bomet   \n","6765                   22.086248    Bomet   \n","7126                   35.753080    Bomet   \n","...                          ...      ...   \n","1024172                81.492523  Nairobi   \n","1024188                72.363677  Nairobi   \n","1024189                41.212594  Nairobi   \n","1024217                45.291012  Nairobi   \n","1024253               101.285402  Nairobi   \n","\n","                                                 SMOD_name  SMOD_id  \n","5588             Dense and semi-dense urban cluster (Town)        5  \n","5606             Dense and semi-dense urban cluster (Town)        5  \n","5614                 Suburban or peri-urban cells (Suburb)        4  \n","6765                 Suburban or peri-urban cells (Suburb)        4  \n","7126                 Suburban or peri-urban cells (Suburb)        4  \n","...                                                    ...      ...  \n","1024172  Low density rural grids cells (Dispersed rural...        2  \n","1024188  Low density rural grids cells (Dispersed rural...        2  \n","1024189  Low density rural grids cells (Dispersed rural...        2  \n","1024217  Low density rural grids cells (Dispersed rural...        2  \n","1024253  Low density rural grids cells (Dispersed rural...        2  \n","\n","[1706368 rows x 8 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Fetch the labelled data set and the SMOD polygons\n","if type(curation_bucket) == str:\n","\n","    streaming_body = cos_client.get_object(Bucket=curation_bucket, Key=labelled_data_SMOD_parquet)['Body']\n","    print(\"Downloading to local storage :  \" + labelled_data_SMOD_parquet)\n","    with io.FileIO(labelled_data_SMOD_parquet, 'w') as file:\n","        for i in io.BytesIO(streaming_body.read()):\n","            file.write(i)\n","\n","buildings_no_height = pd.read_parquet(labelled_data_SMOD_parquet)\n","buildings_no_height = gpd.GeoDataFrame(buildings_no_height, geometry=shapely.from_wkb(buildings_no_height.geometry))\n","buildings_no_height"]},{"cell_type":"markdown","metadata":{},"source":["## Loop through all tiles and calculate heights stats for all available buildings in tile"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false},"outputs":[],"source":["# treshold for area\n","threshold = 0\n","\n","# cursor = DB2_connection.cursor()\n","dfs = []\n","#images_coords = [[[53020, 66900], [10654, 22308]]]\n","t1 = time.time()\n","\n","# loop through tiles coords\n","for idx, coords in enumerate(images_coords):\n","    init_time = time.time()\n","    with rasterio.open(os.path.join(path_to_tif_folder, heights_tiff_name)) as src:\n","        \n","        # read tiff metadata by coords in order to prepare filtered dataframe\n","        print(coords)\n","        \n","        col_off = coords[1][0]\n","        row_off = coords[0][0]\n","        \n","        width = coords[1][1] - coords[1][0]\n","        height = coords[0][1] - coords[0][0]\n","        \n","        # tiff_data = src.read(1, window=Window(col_off, row_off, width, height))\n","        \n","        lon_upper_left, lat_upper_left = src.xy(coords[0][0], coords[1][0])\n","        lon_down_right, lat_down_right = src.xy(coords[0][1], coords[1][1])\n","\n","        lons_sorted = sorted([lon_upper_left, lon_down_right])\n","        lats_sorted = sorted([lat_upper_left, lat_down_right])\n","        \n","        lon_min = lons_sorted[0]\n","        lon_max = lons_sorted[1]\n","\n","        lat_min = lats_sorted[0]\n","        lat_max = lats_sorted[1]\n","        \n","        areas_covered_by_tifs = create_bounds_dict(path_to_tifs=path_to_tif_folder)\n","\n","        df = buildings_no_height[\n","                (buildings_no_height.latitude >= lat_min) & \\\n","                (buildings_no_height.latitude <= lat_max) & \\\n","                (buildings_no_height.longitude >= lon_min) & \\\n","                (buildings_no_height.longitude <= lon_max)\n","            ].copy()\n","        \n","        \n","        if len(df) > 0:\n","\n","            # coordinates of current tile\n","            col_off = max(coords[1][0] - 1, 0)\n","            row_off = max(coords[0][0] - 1, 0)\n","            width = min(coords[1][1] - coords[1][0] + 1, tiff_width)\n","            height = min(coords[0][1] - coords[0][0] + 1, tiff_height)\n","            \n","            # read tile grayscale layer\n","            tiff_data = src.read(1, window=Window(col_off, row_off, width, height))\n","            print(f\"Images revealed: {len(df)}\")\n","            \n","            # loop through building centroids inside tile\n","            for index, row, in tqdm(df.iterrows(), total=len(df), desc='Height calculation'):\n","                try:\n","\n","                    # lat lon to pixel transformations\n","                    pixel_coordinates = get_pixel_coordinates(row.geometry, areas_covered_by_tifs, src)\n","                    polygon_coordinates = [[pixel_coords[0] - row_off, pixel_coords[1] - col_off] for pixel_coords in pixel_coordinates]\n","                    \n","                    margin = 0\n","                    \n","                    rowcolminmax = get_min_max_values_of_row_col(pixel_coordinates=polygon_coordinates)\n","                    \n","                    img_width = rowcolminmax['rowminmax'][1] - rowcolminmax['rowminmax'][0] \n","                    img_height = rowcolminmax['colminmax'][1] - rowcolminmax['colminmax'][0]\n","                    \n","                    row_start = rowcolminmax['rowminmax'][0]\n","                    row_end = rowcolminmax['rowminmax'][1]\n","                    col_start = rowcolminmax['colminmax'][0]\n","                    col_end = rowcolminmax['colminmax'][1]\n","                    img_array_pre = np.array(tiff_data[row_start : row_end, col_start : col_end])\n","                    \n","\n","                    polygon_coordinates = offset_polygon_coords(polygon_coordinates)\n","                    rowcolminmax = get_min_max_values_of_row_col(pixel_coordinates=polygon_coordinates)\n","\n","                    img_width = rowcolminmax['rowminmax'][1] - rowcolminmax['rowminmax'][0] \n","                    img_height = rowcolminmax['colminmax'][1] - rowcolminmax['colminmax'][0]\n","                    row_start = rowcolminmax['rowminmax'][0]\n","                    row_end = rowcolminmax['rowminmax'][1]\n","                    col_start = rowcolminmax['colminmax'][0]\n","                    col_end = rowcolminmax['colminmax'][1]\n","\n","                    # cut building image from tile\n","                    img_array_pre = np.array(tiff_data[row_start : row_end, col_start : col_end])\n","                    \n","                    # extract building by polygon coords\n","                    absolule_polygon_coordinates = [[pixel_coords[0] - row_start, pixel_coords[1] - col_start] for pixel_coords in polygon_coordinates]\n","                    poly_path=Path(absolule_polygon_coordinates)\n","                    x, y = np.mgrid[:img_height, :img_width]\n","                    coors = np.hstack((x.reshape(-1, 1), y.reshape(-1,1)))\n","                    mask = poly_path.contains_points(coors).reshape(img_height, img_width).T\n","                    \n","                    # create zeros mask\n","                    img_masked=np.zeros((img_width, img_height),dtype=img_array_pre.dtype)\n","\n","                    # put image on zeros mask\n","                    img_masked[mask]=img_array_pre[mask]\n","\n","                    # extract image as list of non zero values\n","                    img_masked_list = list(filter(lambda num: num != 0, img_masked.flatten(order='C')))\n","\n","                    #calculate height statistics\n","                    df.at[index, 'height_mean_by_poly'] = 0 if len(img_masked_list) == 0 else np.mean(img_masked_list)\n","                    df.at[index, 'height_median_by_poly'] = 0 if len(img_masked_list) == 0 else np.median(img_masked_list)\n","                    df.at[index, 'height_max_by_poly'] = 0 if len(img_masked_list) == 0 else np.max(img_masked_list)\n","                    df.at[index, 'height_categorized'] = 3 if len(img_masked_list) == 0 else np.median(img_masked_list) // 3 * 3 + 3\n","\n","\n","                except Exception as e:\n","                    pass\n","                    # print(f'Height error occured: {e}')\n","\n","            try:\n","                df = df[df.height_categorized > 0]            \n","                print(f'Buildings heights calculated: {len(df)}')\n","\n","                dfs.append(df)\n","            \n","            except Exception as e:\n","                pass\n","            #Update changed height values        \n","            # for row in tqdm(df.itertuples(), total=len(df), desc='ingestion_data'):\n","            #     lon, lat = row.doc_id.split(':')\n","            #     try:\n","            #         # upd_height_db2(lat, lon, row.height_categorized, row.height_max_by_poly, row.height_mean_by_poly, row.height_median_by_poly, cursor)\n","            #     except Exception as e:\n","            #         print(f\"Error of database: {e}\")\n","            #         DB2_connection = connect_to_db()\n","            #         cursor = DB2_connection.cursor()\n","            #         # upd_height_db2(lat, lon, row.height_categorized, row.height_max_by_poly, row.height_mean_by_poly, row.height_median_by_poly, cursor)\n","            \n","            print(f'Image tile processed, time took: {time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - init_time)))}')\n","    #         if idx == 16:\n","    #             break\n","            \n","            \n","        \n","print(\"\")\n","print(f'All tiles processed, time took: {time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - t1)))}')\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["main_df = pd.concat(dfs)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["main_df = main_df.drop_duplicates(subset='geometry')"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["main_df.to_parquet(labelled_data_SMOD_heights_parquet)\n","\n","# optionaly upload file to the bucket\n","if type(curation_bucket) == str:\n","        \n","    try:\n","        cos_client.upload_file(\n","            Filename=labelled_data_SMOD_heights_parquet,\n","            Bucket=curation_bucket,\n","            Key=labelled_data_SMOD_heights_parquet,\n","            ExtraArgs={'ContentDisposition': 'attachment'}\n","        )\n","           \n","        print(f'File {labelled_data_SMOD_heights_parquet} successfully uploaded to the COS {curation_bucket} bucket')\n","    except Exception as e:\n","        print(f\"\\033[91mFailed upload file to the bucket {curation_bucket}. Error: {e}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":1}

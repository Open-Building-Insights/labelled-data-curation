{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1_fetch_OSM_data_from_DB2\n",
    "### Labelled OSM buildings reside in DB2 already as those were merged to the VIDA data set. This notebook fetches them from the database serving as a basis for the labelled data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial configuration\n",
    "#### To start working with this particular notebook, you need to provide necessary credential and settings\n",
    "#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n",
    "    \"\"\"\n",
    "    {\n",
    "    \"COS_ENDPOINT_URL\": \"s3.private.eu-de.cloud-object-storage.appdomain.cloud\",\n",
    "    \"COS_AUTH_ENDPOINT_URL\": \"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    \"COS_APIKEY\": \"xxx\",\n",
    "    \"DATA_CURATION_BUCKET\": \"xxx\",\n",
    "    \"DB2_CONNECTION_STRING\": \"jdbc:db2://65beb513-5d3d-4101-9001-f42e9dc954b3.brt9d04f0cmqeb8u7740.databases.appdomain.cloud:30371/BLUDB:sslConnection=true;useJDBC4ColumnNameAndLabelSemantics=false;db2.jcc.charsetDecoderEncoder=3;\",\n",
    "    \"DB2_USERNAME\": \"xxx\",\n",
    "    \"DB2_PASSWORD\": \"xxx\",\n",
    "    \"COUNTRY_TABLE\": \"FEATURES_DB_VIDA_EXTENDED\",\n",
    "    \"AREA_THRESHOLD\": 20\n",
    "    }\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read notebook configuration\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "config_str = getpass.getpass('Enter your prepared config: ')\n",
    "config = json.loads(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "import shapely\n",
    "import jaydebeapi as jdbc\n",
    "import jpype\n",
    "import os\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "geod = Geod(ellps=\"WGS84\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_labelled_parquet = \"ML_OSM_dataset.parquet\"\n",
    "curation_bucket = config[\"DATA_CURATION_BUCKET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init S3 client in order to upload data to the curation bucket\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "                              ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "                              ibm_auth_endpoint=config[\"COS_AUTH_ENDPOINT_URL\"],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config[\"COS_ENDPOINT_URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the IBM DB2 function\n",
    "def connect_to_db():\n",
    "\n",
    "    jar = 'db2jcc4.jar'\n",
    "    os.environ['CLASSPATH'] = jar\n",
    "\n",
    "    args='-Djava.class.path=%s' % jar\n",
    "    jvm_path = jpype.getDefaultJVMPath()\n",
    "    try:\n",
    "        jpype.startJVM(jvm_path, args)\n",
    "    except Exception as e:\n",
    "        print('startJVM exception: ', e)\n",
    "        \n",
    "    if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():\n",
    "        jpype.attachThreadToJVM()\n",
    "        jpype.java.lang.Thread.currentThread().setContextClassLoader(jpype.java.lang.ClassLoader.getSystemClassLoader())\n",
    "        \n",
    "    # create JDBC connection\n",
    "    conn = jdbc.connect(\n",
    "                'com.ibm.db2.jcc.DB2Driver',\n",
    "                config['DB2_CONNECTION_STRING'],\n",
    "                [config[\"DB2_USERNAME\"], config[\"DB2_PASSWORD\"]],\n",
    "                'db2jcc4.jar')\n",
    "    \n",
    "    return conn\n",
    "\n",
    "\n",
    "def get_osm_entries():\n",
    "    '''\n",
    "        Fetch all OSM buildings from desired DB2 table\n",
    "    '''\n",
    "    columns = ['id', 'latitude', 'longitude', 'polygon_coordinates', 'vida_confidence', 'osm_type']\n",
    "    \n",
    "    # sql statement for selecting entries by defined rectangle boundaries\n",
    "    sql = f\"\"\"\n",
    "        SELECT {', '.join(columns)} FROM USER1.{config[\"COUNTRY_TABLE\"]}\n",
    "        WHERE \n",
    "            (AREA_IN_METERS > {config[\"AREA_THRESHOLD\"]}) AND\n",
    "            (FOOTPRINT_SOURCE = 'osm')\n",
    "        \"\"\"\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        data = cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Fetch items error occured: {e}\")\n",
    "        print(\"Reconnecting to the database try again...\")\n",
    "\n",
    "        conn = connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql)\n",
    "        data = cursor.fetchall()\n",
    "    finally:\n",
    "        # reshape obtained data to the GeoDataFrame\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        df = gpd.GeoDataFrame(df, geometry=shapely.from_wkt(df.polygon_coordinates.astype(str)))\n",
    "        df = df.drop(['polygon_coordinates'], axis=1)\n",
    "        df['building_area_in_meters'] = df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n",
    "\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch & save buildings to the parquet file\n",
    "ML_OSM_df = get_osm_entries()\n",
    "ML_OSM_df.to_parquet(osm_labelled_parquet)\n",
    "\n",
    "# optionaly upload file to the bucket\n",
    "if type(curation_bucket) == str:\n",
    "        \n",
    "    try:\n",
    "        cos_client.upload_file(\n",
    "            Filename=osm_labelled_parquet,\n",
    "            Bucket=curation_bucket,\n",
    "            Key=osm_labelled_parquet,\n",
    "            ExtraArgs={'ContentDisposition': 'attachment'}\n",
    "        )\n",
    "           \n",
    "        print(f'File {osm_labelled_parquet} successfully uploaded to the COS {curation_bucket} bucket')\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91mFailed upload file to the bucket {curation_bucket}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

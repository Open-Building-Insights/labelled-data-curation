{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2_buildings_filter_special_entries\n",
    "### Cross-references VIDA buildings with OSM amenity, landuse and other tags. Please see the cell belov defining the cross-referencing logic, change it based on your needs and use cases. The labelling of buildings is also handled based on a logic defined in the penultimate cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial configuration\n",
    "#### To start working with this particular notebook, you need to provide necessary credential and settings\n",
    "#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n",
    "    \"\"\"\n",
    "    {\n",
    "    \"COS_ENDPOINT_URL\": \"s3.private.eu-de.cloud-object-storage.appdomain.cloud\",\n",
    "    \"COS_AUTH_ENDPOINT_URL\": \"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    \"COS_APIKEY\": \"xxx\",\n",
    "    \"DATA_CURATION_BUCKET\": \"xxx\",\n",
    "    \"DB2_CONNECTION_STRING\": \"jdbc:db2://65beb513-5d3d-4101-9001-f42e9dc954b3.brt9d04f0cmqeb8u7740.databases.appdomain.cloud:30371/BLUDB:sslConnection=true;useJDBC4ColumnNameAndLabelSemantics=false;db2.jcc.charsetDecoderEncoder=3;\",\n",
    "    \"DB2_USERNAME\": \"xxx\",\n",
    "    \"DB2_PASSWORD\": \"xxx\",\n",
    "    \"COUNTRY_TABLE\": \"FEATURES_DB_VIDA_EXTENDED\",\n",
    "    \"AREA_THRESHOLD\": 20\n",
    "    }\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read notebook configuration\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "config_str = getpass.getpass('Enter your prepared config: ')\n",
    "config = json.loads(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import overpy\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyproj import Geod\n",
    "import shapely\n",
    "import jaydebeapi as jdbc\n",
    "import jpype\n",
    "import os\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "import io\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "overpy_api = overpy.Overpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_labelled_parquet = \"ML_OSM_dataset.parquet\"\n",
    "osm_vida_overpass_parquet = \"OSM_ML+VIDA_overpass_L1.parquet\"\n",
    "curation_bucket = config[\"DATA_CURATION_BUCKET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init S3 client in order to upload data to the curation bucket\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "                              ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "                              ibm_auth_endpoint=config[\"COS_AUTH_ENDPOINT_URL\"],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config[\"COS_ENDPOINT_URL\"])\n",
    "\n",
    "# Fetch the OSM derived training data\n",
    "if type(curation_bucket) == str:\n",
    "    streaming_body = cos_client.get_object(Bucket=curation_bucket, Key=osm_labelled_parquet)['Body']\n",
    "    print(\"Downloading to local storage :  \" + osm_labelled_parquet)\n",
    "    with io.FileIO(osm_labelled_parquet, 'w') as file:\n",
    "        for i in io.BytesIO(streaming_body.read()):\n",
    "            file.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the IBM DB2 function\n",
    "def connect_to_db():\n",
    "\n",
    "    jar = 'db2jcc4.jar'\n",
    "    os.environ['CLASSPATH'] = jar\n",
    "\n",
    "    args='-Djava.class.path=%s' % jar\n",
    "    jvm_path = jpype.getDefaultJVMPath()\n",
    "    try:\n",
    "        jpype.startJVM(jvm_path, args)\n",
    "    except Exception as e:\n",
    "        print('startJVM exception: ', e)\n",
    "        \n",
    "    if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():\n",
    "        jpype.attachThreadToJVM()\n",
    "        jpype.java.lang.Thread.currentThread().setContextClassLoader(jpype.java.lang.ClassLoader.getSystemClassLoader())\n",
    "        \n",
    "    # create JDBC connection\n",
    "    conn = jdbc.connect(\n",
    "                'com.ibm.db2.jcc.DB2Driver',\n",
    "                config['DB2_CONNECTION_STRING'],\n",
    "                [config[\"DB2_USERNAME\"], config[\"DB2_PASSWORD\"]],\n",
    "                'db2jcc4.jar')\n",
    "    \n",
    "    return conn\n",
    "\n",
    "def fetch_builings_in_bbox(cursor, lon_min, lon_max, lat_min, lat_max):\n",
    "    '''\n",
    "        This particular function is aimed for obtating all entries from defined rectangle for selected SQL table\n",
    "    '''\n",
    "\n",
    "    # fetch column names from defined SQL table\n",
    "\n",
    "    columns = ['latitude', 'longitude', 'polygon_coordinates', 'vida_confidence']\n",
    "    \n",
    "    # sql statement for selecting entries by defined rectangle boundaries\n",
    "    sql = f\"\"\"\n",
    "        SELECT {', '.join(columns)} FROM USER1.{config[\"COUNTRY_TABLE\"]}\n",
    "        WHERE \n",
    "            (LATITUDE >= {lat_min}) AND \n",
    "            (LATITUDE <= {lat_max}) AND \n",
    "            (LONGITUDE >= {lon_min}) AND \n",
    "            (LONGITUDE <= {lon_max}) AND\n",
    "            (AREA_IN_METERS > {config[\"AREA_THRESHOLD\"]}) AND\n",
    "            (FOOTPRINT_SOURCE != 'osm')\n",
    "        \"\"\"\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        data = cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Fetch items error occured: {e}\")\n",
    "        print(\"Reconnecting to the database try again...\")\n",
    "\n",
    "        conn = connect_to_db()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql)\n",
    "        data = cursor.fetchall()\n",
    "    finally:\n",
    "        # reshape obtained data to the GeoDataFrame\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        df = gpd.GeoDataFrame(df, geometry=shapely.from_wkt(df.polygon_coordinates.astype(str)))\n",
    "        df = df.drop(['polygon_coordinates'], axis=1)\n",
    "        df['building_area_in_meters'] = df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines the conditions used for cross-referencing\n",
    "conditions = {\n",
    "    'amenity=place_of_worship': {'source': \"OSM\"},\n",
    "    'amenity=library': {'source': \"OSM\"},\n",
    "    'amenity=fuel': {'source': \"OSM\"},\n",
    "    'landuse=greenhouse_horticulture': {'source': \"VIDA\", \"area_filters\": None},\n",
    "    'landuse=industrial': {'source': \"VIDA\", \"area_filters\": {\"min_building\": 50, 'max_entire_area': None}},\n",
    "    'landuse=institutional': {'source': \"VIDA\", \"area_filters\": None},\n",
    "    'landuse=commercial': {'source': \"VIDA\", \"area_filters\": None},\n",
    "    'amenity=college': {'source': \"VIDA\", \"area_filters\": {\"min_building\": 50, 'max_entire_area': 100_000}},\n",
    "    'amenity=hospital': {'source': \"VIDA\", \"area_filters\": {\"min_building\": 50, \"max_building\": 1500, 'max_entire_area': 60_000}},\n",
    "    'amenity=school': {'source': \"VIDA\", \"area_filters\": {\"min_building\": 50, \"max_building\": 1500, 'max_entire_area': 60_000}},\n",
    "    'shop=mall': {'source': 'OSM'},\n",
    "    'tourism=hotel': {'source': 'OSM'},\n",
    "    'shop=car': {'source': 'OSM'},\n",
    "    'office=diplomatic': {'source': 'OSM'},\n",
    "    'diplomatic=embassy': {'source': 'OSM'},\n",
    "    'office=yes': {'source': 'OSM'},\n",
    "    'office=government': {'source': 'OSM'},\n",
    "    'amenity=police': {'source': 'OSM'},\n",
    "    'tourism=hostel': {'source': 'OSM'},\n",
    "    'power=plant': {'source': 'OSM', 'usage': \"nonML\"},\n",
    "    'landuse=quarry': {'source': 'VIDA', 'usage': \"nonML\"},\n",
    "    'aeroway=aerodrome': {'source': 'VIDA', 'usage': \"nonML\"},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(result, query_key, query_value, usage):\n",
    "  \n",
    "  try:\n",
    "      '''Process response from overpass turbo api and return dataframe with queried geometries'''\n",
    "\n",
    "      columns = [\n",
    "        'trusted_source',\n",
    "        'query_key',\n",
    "        'query_value',\n",
    "        'building_tag',\n",
    "        'name',\n",
    "        'properties',\n",
    "        'geometry',\n",
    "        'use_for_training'\n",
    "      ]\n",
    "\n",
    "      data = []\n",
    "      for way in result.ways:\n",
    "\n",
    "          if query_value == 'plant':\n",
    "            properties = f\"PWR: {way.tags.get('plant:output:electricity', 'NA')}, Source: {way.tags.get('plant:source', 'NA')}\"\n",
    "          else:\n",
    "            properties = \", \".join(['{' f'\"{key.replace(\":\", \"_\")}\": '  f'\"{way.tags.get(key).replace(\":\", \"_\")}\"' '}' for key in way.tags.keys()])\n",
    "              \n",
    "          data.append(\n",
    "            [   \n",
    "                f\"OSM_{query_key}\",\n",
    "                query_key,\n",
    "                query_value,\n",
    "                query_value,\n",
    "                way.tags.get('name', ''),\n",
    "                properties,\n",
    "                shapely.geometry.Polygon([[float(point['lon']), float(point['lat'])] for point in way.attributes['geometry']]),\n",
    "                usage\n",
    "            ]\n",
    "          )\n",
    "\n",
    "      df = gpd.GeoDataFrame(data, columns=columns)\n",
    "      \n",
    "      df['land_area_in_meters'] = df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n",
    "      df['building_area_in_meters'] = df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n",
    "\n",
    "      df['longitude'] = df['geometry'].apply(lambda g: g.centroid.xy[0][0])\n",
    "      df['latitude'] = df['geometry'].apply(lambda g: g.centroid.xy[1][0])\n",
    "      \n",
    "      return df\n",
    "  except Exception as e:\n",
    "    print(f'Function process_response exception occured: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_dfs = []\n",
    "conn = connect_to_db()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "for query, condition in conditions.items():\n",
    "    \n",
    "    try:\n",
    "      print('Processing query:', query)\n",
    "      query_key = query.split('=')[0]\n",
    "      query_value = query.split('=')[1]\n",
    "\n",
    "      xml_query = f'''\n",
    "        <osm-script output=\"json\" output-config=\"\" timeout=\"100\">\n",
    "          <query into=\"searchArea\" type=\"area\">\n",
    "            <id-query type=\"area\" ref=\"3601950884\" into=\"searchArea\"/>\n",
    "          </query>\n",
    "          <query into=\"_\" type=\"nwr\">\n",
    "            <has-kv k=\"{query_key}\" modv=\"\" v=\"{query_value}\"/>\n",
    "            <area-query from=\"searchArea\"/>\n",
    "          </query>\n",
    "          <print e=\"\" from=\"_\" geometry=\"full\" ids=\"yes\" limit=\"\" mode=\"body\" n=\"\" order=\"id\" s=\"\" w=\"\"/>\n",
    "        </osm-script>\n",
    "        '''\n",
    "\n",
    "      response = overpy_api.query(xml_query)\n",
    "\n",
    "      usage = condition.get('usage', 'Yes')\n",
    "      \n",
    "      df = process_response(response, query_key, query_value, usage)\n",
    "\n",
    "\n",
    "      if condition['source'] == \"OSM\":\n",
    "          \n",
    "          collected_dfs.append(df)\n",
    "\n",
    "      elif condition['source'] == \"VIDA\":\n",
    "\n",
    "          min_building_filter = None\n",
    "          max_entire_area_filter = None\n",
    "          max_building_filter = None\n",
    "          \n",
    "          area_filters = condition.get('area_filters')\n",
    "          \n",
    "          if area_filters != None:\n",
    "              min_building_filter = condition['area_filters']['min_building']\n",
    "              max_building_filter = condition['area_filters'].get('max_building', None)\n",
    "              \n",
    "              max_entire_area_filter = condition['area_filters']['max_entire_area']\n",
    "              \n",
    "              if max_entire_area_filter != None:\n",
    "                  df = df[df.land_area_in_meters <= max_entire_area_filter]\n",
    "              \n",
    "          for idx, area_metadata in enumerate(tqdm(df.itertuples(), desc='Processing polygons', total=len(df))):\n",
    "      \n",
    "              # get district rectangle boundaried (minx, miny, maxx, maxy)\n",
    "              min_lon, min_lat, max_lon, max_lat = area_metadata.geometry.bounds\n",
    "\n",
    "              # fetch entries in district boundaries\n",
    "              builings_in_bbox = fetch_builings_in_bbox(cursor, min_lon, max_lon, min_lat, max_lat)\n",
    "\n",
    "              # keep only buildings inside district polygon\n",
    "              builings_in_bbox['buildings_in_polygon'] = [area_metadata.geometry.contains(shapely.Point(row.longitude, row.latitude)) for row in builings_in_bbox.itertuples()]\n",
    "              builings_in_polygon = builings_in_bbox[builings_in_bbox['buildings_in_polygon'] == True]\n",
    "              if len(builings_in_polygon) > 0:\n",
    "                  builings_in_polygon = builings_in_polygon.drop(['buildings_in_polygon'], axis=1)\n",
    "                  builings_in_polygon['trusted_source'] = ['from_VIDA' for _ in range(len(builings_in_polygon))]\n",
    "                  builings_in_polygon['building_tag'] = [area_metadata.query_value for _ in range(len(builings_in_polygon))]\n",
    "                  builings_in_polygon['land_area_in_meters'] = [area_metadata.land_area_in_meters for _ in range(len(builings_in_polygon))]\n",
    "                  \n",
    "                  builings_in_polygon['name'] = [area_metadata.name for _ in range(len(builings_in_polygon))]\n",
    "                  builings_in_polygon['properties'] = [area_metadata.properties for _ in range(len(builings_in_polygon))]\n",
    "                  \n",
    "                  builings_in_polygon['query_key'] = [area_metadata.query_key for _ in range(len(builings_in_polygon))]\n",
    "                  builings_in_polygon['query_value'] = [area_metadata.query_value for _ in range(len(builings_in_polygon))]\n",
    "                  \n",
    "                  \n",
    "                  if min_building_filter != None:\n",
    "                      builings_in_polygon = builings_in_polygon[builings_in_polygon.building_area_in_meters > min_building_filter]\n",
    "                      \n",
    "                  if max_building_filter != None:\n",
    "                      builings_in_polygon = builings_in_polygon[builings_in_polygon.building_area_in_meters < max_building_filter]\n",
    "                    \n",
    "                      \n",
    "                  collected_dfs.append(builings_in_polygon)\n",
    "              # print(f'buildings in polygoon {len(df)}')\n",
    "    except Exception as ex:\n",
    "      print(f\"query error occured: {ex}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat(collected_dfs)\n",
    "main_df['id'] = main_df['longitude'].astype(str) + ':' + main_df['latitude'].astype(str)\n",
    "main_df['osm_type'] = main_df['building_tag']\n",
    "main_df['vida_confidence'] = main_df['vida_confidence'].fillna(1)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Yes': 318718, 'nonML': 238})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['use_for_training'] = main_df['use_for_training'].fillna('Yes')\n",
    "Counter(main_df.use_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_OSM_df = gpd.read_parquet(osm_labelled_parquet)\n",
    "ML_OSM_df['trusted_source'] = ['OSM_DB2_ML' for _ in range(len(ML_OSM_df))]\n",
    "ML_OSM_df['use_for_training'] = ['Yes' for _ in range(len(ML_OSM_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching intersecrions: 100%|██████████| 50271/50271 [07:14<00:00, 115.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of VIDA buildings with intersection: 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "items_to_delete = []\n",
    "\n",
    "for building in tqdm(ML_OSM_df.itertuples(), total=len(ML_OSM_df), desc='Matching intersecrions'):\n",
    "    \n",
    "    near_buildings = main_df[(abs(main_df.longitude - building.longitude) <= 0.006) & (abs(main_df.latitude - building.latitude) <= 0.0006)].copy()\n",
    "    \n",
    "    near_buildings[\"intersection\"] = near_buildings[\"geometry\"].apply(lambda vida_geometry: float(vida_geometry.intersection(building.geometry).area/vida_geometry.area))\n",
    "    \n",
    "    if len(near_buildings) > 0:\n",
    "        revealed_intersections = near_buildings[near_buildings['intersection'] > 0.05]\n",
    "        \n",
    "        items_to_delete += list(revealed_intersections.id)\n",
    "    \n",
    "items_to_delete = list(set(items_to_delete))\n",
    "\n",
    "print(f'Amount of VIDA buildings with intersection: {len(items_to_delete)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df = pd.concat(\n",
    "    [\n",
    "        ML_OSM_df,\n",
    "        main_df[~main_df.id.isin(items_to_delete)]\n",
    "    ]\n",
    ")\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines which buildings belong to which labelled classes for the training purposes\n",
    "def assign_ML_class(osm_type):\n",
    "    # Define category mappings\n",
    "    industrial_types = [\n",
    "        \"industrial\", \"barn\", \"static_caravan\", \"farm_auxiliary\", \"farm\", \"warehouse\", \n",
    "        \"stable\", \"manufacture\", \"store\", \"cowshed\",\n",
    "        #### below are from overpass turbo\n",
    "        'greenhouse_horticulture', 'industrial', 'industry', \"greenhouse\", \"greenhouse_horticult\"\n",
    "    ]\n",
    "    commercial_types = [\n",
    "        \"commercial\", \"office\", \"hotel\", \"retail\", \"kiosk\", \"commercial;yes\", \n",
    "        \"restaurant\", \"kitchen\", \"sports_centre\", \"bakehouse\", \"inn\", \"business\", \n",
    "        \"yes;office\", \"resturant\", \"Wasini hostel\", \"supermarket\"\n",
    "        ####\n",
    "        \n",
    "    ]\n",
    "    public_types = [\n",
    "        \"school\", \"church\", \"hospital\", \"public\", \"monastery\", \"university\", \"mosque\", \n",
    "        \"chapel\", \"service\", \"cathedral\", \"college\", \"stadium\", \"kindergarten\", \"hangar\", \n",
    "        \"transportation\", \"government\", \"train_station\", \"Petrol station\", \"Dispensary\", \n",
    "        \"Medical Laboratory\", \"temple\", \"clinic\", \"convent\", \"civic\", \"Mortuary\",\n",
    "        #### below are from overpass turbo\n",
    "        'institutional', 'place_of_worship', 'library', 'college'\n",
    "    ]\n",
    "    \n",
    "    if osm_type in public_types:\n",
    "        return 'public'\n",
    "    elif osm_type in industrial_types:\n",
    "        return 'industrial'\n",
    "    elif osm_type in commercial_types:\n",
    "        return 'commercial'\n",
    "    else:\n",
    "        return 'residential'\n",
    "    \n",
    "result_df['ML_class'] = result_df['osm_type'].apply(assign_ML_class)\n",
    "result_df['area_in_meters'] = result_df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_parquet(osm_vida_overpass_parquet)\n",
    "\n",
    "# optionaly upload file to the bucket\n",
    "if type(curation_bucket) == str:\n",
    "        \n",
    "    try:\n",
    "        cos_client.upload_file(\n",
    "            Filename=osm_vida_overpass_parquet,\n",
    "            Bucket=curation_bucket,\n",
    "            Key=osm_vida_overpass_parquet,\n",
    "            ExtraArgs={'ContentDisposition': 'attachment'}\n",
    "        )\n",
    "           \n",
    "        print(f'File {osm_vida_overpass_parquet} successfully uploaded to the COS {curation_bucket} bucket')\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91mFailed upload file to the bucket {curation_bucket}. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
